{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as t\n",
    "from mpl_toolkits.basemap import Basemap,shiftgrid,addcyclic\n",
    "from cdo import Cdo,CDOException,CdoTempfileStore\n",
    "cdo=Cdo()\n",
    "\n",
    "mpl.rc(\"text\", usetex=False)\n",
    "mpl.rc('axes',titlesize=20,labelsize=17,linewidth=1.2)\n",
    "mpl.rc('xtick',labelsize=15)\n",
    "mpl.rc('ytick',labelsize=15)\n",
    "mpl.rcParams['xtick.major.size']=5.5\n",
    "mpl.rcParams['xtick.minor.size']=3.5\n",
    "mpl.rcParams['ytick.major.size']=5.5\n",
    "mpl.rcParams['ytick.minor.size']=3.5\n",
    "mpl.rcParams['legend.fontsize']=15\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def graph_Antarctica(path_array,legend_array,name_files,var,year,mesi,\\\n",
    "                     title,ylabel,data172,temp,cost,position=(0.5,-0.16)):\n",
    "    data_mean=np.zeros((len(path_array),12))\n",
    "\n",
    "    for m in range(0,len(path_array)):\n",
    "        if year[m]<10:\n",
    "            string=\"000\"+str(year[m])\n",
    "        elif year[m]>=10 and year[m]<100:\n",
    "            string=\"00\"+str(year[m])\n",
    "        elif year[m]>=100 and year[m]<1000:\n",
    "            string=\"0\"+str(year[m])\n",
    "        else:\n",
    "            string=str(year[m])\n",
    "\n",
    "        \n",
    "        if temp==True:\n",
    "            data=[np.reshape([float(i)*cost for i in  \" \".join(cdo.output(input=\"-addc,-273.15 -selmonth,\"\\\n",
    "                    +str(j)+\" -selname,\"+var+\" \"+path_array[m]+\"../\"+name_files[m]+\"_PLA.\"+string+\".nc\"))\\\n",
    "                              .split()],[nlat,nlon]) for j in range(1,13)]\n",
    "        else:\n",
    "            data=[np.reshape([float(i)*cost for i in  \" \".join(cdo.output(input=\"-selmonth,\"+str(j)\\\n",
    "                                            +\" -selname,\"+var+\" \"+path_array[m]+\"../\"+name_files[m]+\"_PLA.\"\\\n",
    "                                            +string+\".nc\")).split()],[nlat,nlon]) for j in range(1,13)]\n",
    "        lats=Dataset(path_array[m]+\"../\"+name_files[m]+\"_PLA.\"+string+\".nc\",\"r\").variables[\"lat\"][::-1]\n",
    "        data2=np.zeros((len(data),nlon*6*mul))\n",
    "        #print(np.shape(data))\n",
    "        \n",
    "        for k in range(0,len(data)):\n",
    "            count=0\n",
    "            count_mean=0\n",
    "            for i in range(0,len(data[k])):\n",
    "                for j in range(0,len(data[k][i])):\n",
    "                    if i>25*mul:\n",
    "                        if data172[i][j]>=0.5:\n",
    "                            #print(i,j)\n",
    "                            #print(count)\n",
    "                            data2[k][count]=data[k][i][j]*np.cos(np.pi*lats[i]/180)\n",
    "                            count_mean+=np.cos(np.pi*lats[i]/180)\n",
    "                            count+=1\n",
    "        data_mean[m]=[np.sum(i)/count_mean for i in data2]\n",
    "        #print(count)\n",
    "    graph(mesi,data_mean,title+\" Annual Antarctica Cycle\",legend_array,\"upper center\",\"Time [month]\",\\\n",
    "          ylabel,True,False,position=position)\n",
    "    return data_mean\n",
    "\n",
    "def graph_60N(path_array,legend_array,name_files,var,year,mesi,title,ylabel,data172,temp,cost):\n",
    "    data_mean=np.zeros((len(path_array),12))\n",
    "\n",
    "    for m in range(0,len(path_array)):\n",
    "        if year[m]<10:\n",
    "            string=\"000\"+str(year[m])\n",
    "        elif year[m]>=10 and year[m]<100:\n",
    "            string=\"00\"+str(year[m])\n",
    "        elif year[m]>=100 and year[m]<1000:\n",
    "            string=\"0\"+str(year[m])\n",
    "        else:\n",
    "            string=str(year[m])\n",
    "\n",
    "        if temp==True:\n",
    "            data=[np.reshape([float(i)*cost for i in  \" \".join(cdo.output(input=\"-addc,-273.15 -selmonth,\"\\\n",
    "                        +str(j)+\" -selname,\"+var+\" \"+path_array[m]+\"../\"+name_files[m]+\"_PLA.\"+string+\".nc\"))\\\n",
    "                              .split()],[nlat,nlon]) for j in range(1,13)]\n",
    "        else:\n",
    "            data=[np.reshape([float(i)*cost for i in  \" \".join(cdo.output(input=\"-selmonth,\"+str(j)\\\n",
    "                    +\" -selname,\"+var+\" \"+path_array[m]+\"../\"+name_files[m]+\"_PLA.\"+string+\".nc\")).\\\n",
    "                              split()],[nlat,nlon]) for j in range(1,13)]\n",
    "        lats=Dataset(path_array[m]+\"../\"+name_files[m]+\"_PLA.\"+string+\".nc\",\"r\").variables[\"lat\"][::-1]\n",
    "        data2=np.zeros((len(data),nlon*6*mul))\n",
    "        #print(np.shape(data),lats)\n",
    "        \n",
    "        for k in range(0,len(data)):\n",
    "            count=0\n",
    "            count_mean=0\n",
    "            for i in range(0,len(data[k])):\n",
    "                for j in range(0,len(data[k][i])):\n",
    "                    if i<6*mul:\n",
    "                        if data172[i][j]>=0.5:\n",
    "                            data2[k][count]=data[k][i][j]*data172[i][j]*np.cos(np.pi*lats[i]/180)\n",
    "                            count_mean+=data172[i][j]*np.cos(np.pi*lats[i]/180)\n",
    "                            count+=1\n",
    "        data_mean[m]=[np.sum(i)/count_mean for i in data2]\n",
    "        print(count)\n",
    "    graph(mesi,data_mean,title+\" Annual North Cycle\",legend_array,\"upper center\",\"Time [month]\"\\\n",
    "          ,ylabel,True,False)\n",
    "    return data_mean\n",
    "\n",
    "\n",
    "    \n",
    "def read_graph_file(name_file,path,month,title,mesi,column,bar_title,vmin,vmax,cbar_type):\n",
    "    \"\"\"name_file,path,month,title,mesi,column,bar_title,vmin,vmax,cbar_type \"\"\"\n",
    "    if month==True:\n",
    "        with open(path+name_file,'r') as f:\n",
    "            str_data=f.readline()\n",
    "            f.seek(0)\n",
    "            data=[[float(num) for num in line.split()] for line in f]\n",
    "        for i in range(0,int(len(data)*column/tot)):\n",
    "            data_res=np.reshape(data[i*int(tot/column)+1+i:(i+1)*int(tot/column)+1+i],[nlat,nlon])\n",
    "            Title=title+\" \"+mesi[i]\n",
    "            graphycs_v(data_res[::-1],Title,'cyl',cbar_type,False,bar_title,vmin,vmax)\n",
    "        return data,str_data\n",
    "    else: \n",
    "        \n",
    "        with open(path+name_file,'r') as f:\n",
    "            str_data=f.readline()\n",
    "            data=[[float(num) for num in line.split()] for line in f]\n",
    "        data_res=np.reshape(data,[nlat,nlon])\n",
    "        graphycs_v(data_res[::-1],title,'cyl',cbar_type,False,bar_title,vmin,vmax)\n",
    "        return data_res,str_data\n",
    "    \n",
    "def graphycs_v(data_array,title,proj,bar,savefig,bar_title,vmn,vmx):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    m = Basemap(projection=proj, llcrnrlat=-90, urcrnrlat=90,\\\n",
    "                llcrnrlon=0, urcrnrlon=360, resolution='c', lon_0=0)\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90,91,30),labels=[1,0,0,0])\n",
    "    m.drawmeridians(np.arange(-180.,181.,60.),labels=[0,0,0,1])\n",
    "    m.imshow(data_array,cmap=bar,vmax=vmx,vmin=vmn)\n",
    "    cbar = plt.colorbar(orientation='vertical', shrink=0.5)\n",
    "    cbar.set_label(bar_title,rotation=-90,fontsize=14,labelpad=25)\n",
    "    plt.title(title+\"\\n\",fontsize=17,fontweight=\"bold\")\n",
    "    if savefig==True :\n",
    "        fig.savefig(\"grafici/\"+title,bbox_inches='tight')\n",
    "\n",
    "def graph(x,data_array,title,legend_array,loc_legend,xlabel,ylabel,save,zonal,position=(0.5,-0.16)):\n",
    "    fig,ax=plt.subplots(figsize=(7,5))\n",
    "\n",
    "    for i in range(0,len(data_array)):\n",
    "        ax.plot(x[i],data_array[i],label=legend_array[i])\n",
    "    legend=ax.legend(loc=\"best\", shadow=True)\n",
    "    ax.set_title(title+\"\\n\",fontweight=\"bold\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.yaxis.set_minor_locator(t.AutoMinorLocator())\n",
    "\n",
    "    if zonal==True:\n",
    "        ax.set_xlim(-90,90)\n",
    "        ax.xaxis.set_minor_locator(t.MultipleLocator(10))\n",
    "        ax.set_xticks((90,60,30,0,-30,-60,-90))\n",
    "        ax.set_xticklabels([\"90N\",\"60N\",\"30N\",\"0\",\"30S\",\"60S\",\"90S\"])\n",
    "\n",
    "        ax.grid(linestyle='--')   \n",
    "    elif \"Cycle\" in title:\n",
    "        ax.grid(axis='y',linestyle='--')\n",
    "    else:\n",
    "        ax.grid(axis='y',linestyle='--')\n",
    "        #ax.xaxis.set_major_locator(t.MultipleLocator(20))\n",
    "    plt.show()\n",
    "    if save==True:\n",
    "        fig.savefig(\"grafici/\"+title,bbox_inches='tight')\n",
    "    data=[]\n",
    "              \n",
    "def load_file1(cost,file_array,path_array):\n",
    "    data=[]\n",
    "              \n",
    "        \n",
    "        \n",
    "    if \"ZM\" in file_array[0]:\n",
    "        data=[[cost*i for i in np.reshape(Dataset(path_array[j]+file_array[j],\"r\").\\\n",
    "                    variables[file_array[j].split(\"_\")[-1].replace(\".nc\",\"\") ][:],[nlat])]\\\n",
    "              for j in range(0,len(file_array))]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #print(np.shape(Dataset(path_array[0]+file_array[0],\"r\").variables[file_array[0].split(\"_\")[-1].replace(\".nc\",\"\") ][:]))\n",
    "        data=[[cost*i for i in np.reshape(Dataset(path_array[j]+file_array[j],\"r\").variables[file_array[j]\\\n",
    "            .split(\"_\")[-1].replace(\".nc\",\"\") ][:],[int(file_array[j].split(\"_\")[-2].replace(\"Y\",\"\"))])]\\\n",
    "              for j in range(0,len(file_array))]\n",
    "        #print(\"1\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "def load_file2(cost,file_array,path_array,typology,temp,step,start):\n",
    "                 \n",
    "    if typology==\"global\":\n",
    "        data=[[cost*float(j) for j in np.reshape([cdo.output(input=\"-timselmean,\"+str(step[k])+\",\"\\\n",
    "                                                             +str(start[k])+\" -selmonth,\"+str(i)\\\n",
    "                                                        +\" \"+path_array[k]+file_array[k]) for i in\\\n",
    "                                                  range(1,13)],[12])] for k in range(0,len(file_array))]\n",
    "    \n",
    "    elif typology==\"south\":\n",
    "        if temp==True:\n",
    "            data0=[[cdo.output(input=\"-gridboxmean,nlon,16 -timselmean,\"+str(step[k])+\\\n",
    "                                                  \",\"+str(start[k])+\" -addc,-273.15 -selmonth,\"+str(i)+\" \"+\\\n",
    "                                                  path_array[k]+file_array[k])[0].split() for i in \\\n",
    "                    range(1,13)]\\\n",
    "                                                   for k in range(0,len(file_array))]\n",
    "        else:\n",
    "            data0=[[cdo.output(input=\"-gridboxmean,nlon,16 -timselmean,\"+str(step[k])+\\\n",
    "                                        \",\"+str(start[k])+\" -selmonth,\"+str(i)+\" \"+\\\n",
    "                                            path_array[k]+file_array[k])[0].split() for i in range(1,13)]\\\n",
    "                                            for k in range(0,len(file_array))]\n",
    "\n",
    "        data=[[cost*float(data0[k][i][1]) for i in range(0,len(data0[k]))] for k in range(0,len(data0))]\n",
    "    elif typology==\"north\":\n",
    "        if temp==True:\n",
    "            data0=[[cdo.output(input=\"-gridboxmean,nlon,16 -timselmean,\"+str(step[k])+\\\n",
    "                                                  \",\"+str(start[k])+\" -addc,-273.15 -selmonth,\"+str(i)+\" \"+\\\n",
    "                                                  path_array[k]+file_array[k])[0].split() for i \\\n",
    "                    in range(1,13)]\\\n",
    "                                                   for k in range(0,len(file_array))]\n",
    "        else:\n",
    "            data0=[[cdo.output(input=\"-gridboxmean,nlon,16 -timselmean,\"+str(step[k])+\\\n",
    "                                        \",\"+str(start[k])+\" -selmonth,\"+str(i)+\" \"+\\\n",
    "                                            path_array[k]+file_array[k])[0].split() for i in range(1,13)]\\\n",
    "                                            for k in range(0,len(file_array))]\n",
    "\n",
    "        data=[[cost*float(data0[k][i][0]) for i in range(0,len(data0[k]))] for k in range(0,len(data0))]\n",
    "    else:\n",
    "        print(\"input sbagliato\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def graph_globe(data,lons,lats,proj,save,title,cbar_title,vmn,vmx,step_bar,cmap=plt.cm.jet_r):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    m = Basemap(projection=proj, llcrnrlat=-90, urcrnrlat=90,\\\n",
    "            llcrnrlon=0, urcrnrlon=360, resolution='c', lon_0=0)\n",
    "    m.drawcoastlines()\n",
    "    if proj==\"cyl\":\n",
    "        m.drawparallels(np.arange(-90,91,30),labels=[1,0,0,0])\n",
    "        m.drawmeridians(np.arange(-180.,181.,60.),labels=[0,0,0,1])\n",
    "        m.imshow(data[::-1],cmap=cmap,vmin=vmn,vmax=vmx)\n",
    "        cbar = plt.colorbar(orientation='vertical', shrink=0.5,ticks=np.linspace(vmn,vmx,step_bar))\n",
    "    else:\n",
    "        m.drawmapboundary()\n",
    "        m.drawparallels(np.arange(-90,90,30),labels=[1,0,0,0])\n",
    "        m.drawmeridians(np.arange(m.lonmin,m.lonmax+30,60),labels=[0,0,0,1])\n",
    "        var_cyclic, lons_cyclic = addcyclic(data,lons)\n",
    "        var_cyclic, lons_cyclic = shiftgrid(180.,var_cyclic,lons_cyclic,start=False)\n",
    "        lon2d, lat2d = np.meshgrid(lons_cyclic, lats)\n",
    "        x,y = m(lon2d, lat2d)\n",
    "        \n",
    "        cs = m.contourf(x,y,var_cyclic, cmap=cmap,levels=t.MaxNLocator(nbins=step_bar)\\\n",
    "                        .tick_values(vmn,vmx),extend=\"both\")\n",
    "        cbar = plt.colorbar(cs,orientation='vertical', shrink=0.5,ticks=t.MaxNLocator\\\n",
    "                            (nbins=step_bar).tick_values(vmn,vmx))\n",
    "\n",
    "       \n",
    "    cbar.set_label(cbar_title,rotation=-90,labelpad=25)\n",
    "    plt.title(title+\"\\n\",fontweight=\"bold\")\n",
    "    if save==True:\n",
    "        fig.savefig(\"grafici/\"+title,bbox_inches='tight')\n",
    "\n",
    "def print_value(data,starts,ends):\n",
    "   \n",
    "    for i in range(0,len(data)):\n",
    "          print(\"Mean \"+str(starts[i])+\"-\"+str(ends[i])+\": \"+str(np.mean(data[i][starts[i]:ends[i]]))\\\n",
    "              +\" dev.std: \"+str(np.std(data[i][starts[i]:ends[i]])))\n",
    "\n",
    "            \n",
    "def Net_Flux_Sup(nome_file,type_file,path_arrays,lenght,load_file,typology,temp,step,start):\n",
    "    var=[\"rls\",\"rss\",\"hfss\",\"hfls\",\"prsn\"]\n",
    "    path_array=[path_arrays for i in range(0,len(var))]\n",
    "    if load_file==1:\n",
    "        data=load_file1(1,[nome_file+type_file+i+\".nc\" for i in var],path_array)\n",
    "    else:\n",
    "        data=load_file2(1,[nome_file+type_file+i+\".nc\" for i in var],path_array,typology,temp,\\\n",
    "                        [step for i in range(0,len(var))],[start for i in range(0,len(var))] )\n",
    "       \n",
    "    data0=np.reshape(data[0],[lenght])+np.reshape(data[1],[lenght])+np.reshape(data[2],[lenght])+\\\n",
    "    np.reshape(data[3],[lenght])-1000*334000*np.reshape(data[4],[lenght])\n",
    "    return np.reshape(data0,[lenght])\n",
    "\n",
    "def all_graph(var,title_var,ylabel,name_files,path_array,legend_array,starts,ends,step,lats,lons,mesi\\\n",
    "              ,cost,temp,string=\"ab\",position=(0.5,-0.16)):\n",
    "    if \"a\" in string:\n",
    "        #Global Annual Cycle\n",
    "        in_global=[name_files[i]+\"_YM_FM_\"+str(ends[i])+\"Y_\"+var+\".nc\" for i in range(0,len(name_files))]\n",
    "        data_global=load_file1(cost,in_global,path_array)\n",
    "        graph(time,data_global,title_var+\" Global Annual Mean\",legend_array,\"upper center\",\"Time [year]\"\\\n",
    "              ,ylabel,True,False,position)\n",
    "        print_value(data_global,starts,ends)\n",
    "    else: \n",
    "        data_global=0\n",
    "    if \"b\" in string:\n",
    "        #Zonal\n",
    "        in_zonal=[name_files[i]+\"_YM_\"+str(step[i])+\"YM_ZM_\"+str(ends[i])+\"Y_\"+var+\".nc\" for i in \\\n",
    "                  range(0,len(name_files))]\n",
    "        data_zonal=load_file1(cost,in_zonal,path_array)\n",
    "        graph(lats,data_zonal,title_var+\" Zonal Mean\",legend_array,\"upper center\",\"Latitude [째]\",ylabel,\\\n",
    "              True,True,position)\n",
    "    else:\n",
    "        data_zonal=0\n",
    "    if \"c\" in string:\n",
    "        #1 year cycle\n",
    "        #Global\n",
    "        in_global_cycle=[name_files[i]+\"_FM_\"+str(ends[i])+\"Y_\"+var+\".nc\" for i in range(0,len(name_files))]\n",
    "        data_global_cycle=load_file2(cost,in_global_cycle,path_array,\"global\",temp,step,starts)\n",
    "        graph(mesi,data_global_cycle,title_var+\" Global Annual Cycle\",legend_array,\"upper center\",\"Time [month]\",\\\n",
    "              ylabel,True,False,position)\n",
    "    else:\n",
    "        data_global_cycle=0\n",
    "    if \"n\" in string:\n",
    "        #North\n",
    "        in_north_cycle=[i+\"_all_\"+var+\".nc\" for i in name_files]\n",
    "        data_north_cycle=load_file2(cost,in_north_cycle,path_array,\"north\",temp,step,starts)\n",
    "        graph(mesi,data_north_cycle,title_var+\" North Annual Cycle\",legend_array,\"upper center\",\"Time [month]\",\\\n",
    "              ylabel,True,False,position)\n",
    "    else:\n",
    "        data_north_cycle=0\n",
    "    if \"s\" in string:\n",
    "        #South\n",
    "        in_south_cycle=[i+\"_all_\"+var+\".nc\" for i in name_files]\n",
    "        data_south_cycle=load_file2(cost,in_south_cycle,path_array,\"south\",temp,step,starts)\n",
    "        graph(mesi,data_south_cycle,title_var+\" South Annual Cycle\",legend_array,\"upper center\",\"Time [month]\",\\\n",
    "          ylabel,True,False,position)\n",
    "    else:\n",
    "        data_south_cycle=0\n",
    "    \n",
    "    return data_global,data_zonal,data_global_cycle,data_north_cycle,data_south_cycle\n",
    "\n",
    "\n",
    "\n",
    "def all_graph_res(var,title_var,ylabel,name_files,path_array,legend_array,starts,ends,step,lats,lons,mesi,cost,\\\n",
    "                  temp):\n",
    "    #Global Annual Cycle\n",
    "    in_global=[name_files[i]+\"_YM_FM_\"+str(ends[i])+\"Y_\"+var+\".nc\" for i in range(0,len(name_files))]\n",
    "    data_global=load_file1(cost,in_global,path_array)\n",
    "    graph(time,data_global,title_var+\" Global Annual Mean\",legend_array,\"upper center\",\"Time [year]\",ylabel,\\\n",
    "          True,False)\n",
    "    print_value(data_global,starts,ends)               \n",
    "    #Zonal\n",
    "    in_zonal=[name_files[i]+\"_YM_\"+str(step[i])+\"YM_ZM_\"+str(ends[i])+\"Y_\"+var+\".nc\" for i in range(0,len(name_files))]\n",
    "    data_zonal=load_file1(cost,in_zonal,path_array)\n",
    "    graph(lats,data_zonal,title_var+\" Zonal Mean\",legend_array,\"upper left\",\"Latitude [째]\",ylabel,True,True)\n",
    " \n",
    "    return data_global,data_zonal\n",
    "\n",
    "def all_graph_sum(var1,var2,title_var,ylabel,name_files,path_array,legend_array,starts,\\\n",
    "                  ends,step,lats,lons,mesi,cost,temp,string=\"ab\",position=(0.5,-0.16)):\n",
    "    if \"a\" in string:\n",
    "        #Global Annual Cycle\n",
    "        in_global1=[name_files[i]+\"_YM_FM_\"+str(ends[i])+\"Y_\"+var1+\".nc\" for i in range(0,len(name_files))]\n",
    "        in_global2=[name_files[i]+\"_YM_FM_\"+str(ends[i])+\"Y_\"+var2+\".nc\" for i in range(0,len(name_files))]\n",
    "        data_global=[np.add(load_file1(cost,in_global1,path_array)[i],load_file1(cost,in_global2,path_array)\\\n",
    "                            [i]) for i in range(0,len(name_files))]\n",
    "   \n",
    "        graph(time,data_global,title_var+\" Global Annual Mean\",legend_array,\"upper center\",\"Time [year]\",\\\n",
    "          ylabel,True,False,position)\n",
    "        print_value(data_global,starts,ends) \n",
    "    else:\n",
    "        data_global=0\n",
    "    if \"b\" in string:\n",
    "        \n",
    "        #Zonal\n",
    "        in_zonal1=[name_files[i]+\"_YM_\"+str(step[i])+\"YM_ZM_\"+str(ends[i])+\"Y_\"+var1+\".nc\" for i in range(0,len(name_files))]\n",
    "        in_zonal2=[name_files[i]+\"_YM_\"+str(step[i])+\"YM_ZM_\"+str(ends[i])+\"Y_\"+var2+\".nc\" for i in range(0,len(name_files))]\n",
    "        data_zonal=[np.add(load_file1(cost,in_zonal1,path_array)[i],load_file1(cost,in_zonal2,path_array)[i])\\\n",
    "                    for i in range(0,len(name_files))]\n",
    "        #print(np.shape(data_zonal))\n",
    "        graph(lats,data_zonal,title_var+\" Zonal Mean\",legend_array,\"upper center\",\"Latitude [째]\",ylabel,\\\n",
    "              True,True,position)\n",
    "    else:\n",
    "        data_zonal=0\n",
    "    if \"c\" in string:\n",
    "        \n",
    "        #1 year cycle\n",
    "        #Global\n",
    "        in_global_cycle1=[name_files[i]+\"_FM_\"+str(ends[i])+\"Y_\"+var1+\".nc\" for i in range(0,len(name_files))]\n",
    "        in_global_cycle2=[name_files[i]+\"_FM_\"+str(ends[i])+\"Y_\"+var2+\".nc\" for i in range(0,len(name_files))]\n",
    "        data_global_cycle=[np.add(load_file2(cost,in_global_cycle1,path_array,\"global\",temp,step,starts)[i],\\\n",
    "                                  load_file2(cost,in_global_cycle2,path_array,\"global\",temp,step,starts)[i])\\\n",
    "                       for i in range(0,len(name_files))]\n",
    "        graph(mesi,data_global_cycle,title_var+\" Global Annual Cycle\",legend_array,\"upper center\",\"Time [month]\",\\\n",
    "              ylabel,True,False,position)\n",
    "    else:\n",
    "        data_global_cycle=0\n",
    "    if \"n\" in string:\n",
    "        #North\n",
    "        in_north_cycle1=[i+\"_all_\"+var1+\".nc\" for i in name_files]\n",
    "        in_north_cycle2=[i+\"_all_\"+var2+\".nc\" for i in name_files]\n",
    "        data_north_cycle=[np.add(load_file2(cost,in_north_cycle1,path_array,\"north\",\\\n",
    "                                        temp,step,starts)[i],load_file2(cost,in_north_cycle2,path_array,\\\n",
    "                                                                      \"north\",temp,step,starts)[i]) \\\n",
    "                          for i in range(0,len(name_files))]\n",
    "        graph(mesi,data_north_cycle,title_var+\" North Annual Cycle\",legend_array,\\\n",
    "              \"upper center\",\"Time [month]\",ylabel,True,False,position)\n",
    "    else:\n",
    "        data_north_cycle=0\n",
    "    if \"s\" in string:\n",
    "        #South\n",
    "        in_south_cycle1=[i+\"_all_\"+var1+\".nc\" for i in name_files]\n",
    "        in_south_cycle2=[i+\"_all_\"+var2+\".nc\" for i in name_files]\n",
    "        data_south_cycle=[np.add(load_file2(cost,in_south_cycle1,path_array,\"south\",\\\n",
    "                                        temp,step,starts)[i],load_file2(cost,in_south_cycle2,path_array,\\\n",
    "                                                                      \"south\",temp,step,starts)[i]) \\\n",
    "                      for i in range(0,len(name_files))]\n",
    "        graph(mesi,data_south_cycle,title_var+\" South Annual Cycle\",legend_array,\\\n",
    "              \"upper center\",\"Time [month]\",ylabel,True,False,position)\n",
    "    else:\n",
    "        data_south_cycle=0\n",
    "    \n",
    "    return data_global,data_zonal,data_global_cycle,data_north_cycle,data_south_cycle\n",
    "\n",
    "def graph_level(var,title_var,ylabel,name_files,path_array,ends,steps,z_press,lat,cost,var_min,var_max):\n",
    "    data_globe=[[cost*i for i in Dataset(path_array[j]+name_files[j]+\"_YM_\"+str(steps[j])+\"YM_ZM_\"+str(ends[j])+\"Y_\"+var+\".nc\").\\\n",
    "                 variables[var][:]]for j in range(0,len(name_files))]\n",
    "\n",
    "\n",
    "    for i in range(0,len(name_files)):\n",
    "        for j in range(i+1,len(name_files)):\n",
    "            fig,ax=plt.subplots(figsize=(8,6))\n",
    "            x,y=np.meshgrid(lat,z_press)\n",
    "            cs=ax.contourf(x,y,np.reshape(data_globe[i],(13,nlat))-np.reshape(data_globe[j],(13,nlat)),\\\n",
    "                           cmap=plt.cm.jet,levels=np.linspace(var_min,var_max,21),extend=\"both\")\n",
    "            #ax.xaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "            ax.yaxis.set_ticks([1000,850,700,500,400,300,200,100,30])\n",
    "            ax.set_ylim(1000,30)\n",
    "            ax.set_xlabel(\"Latitude [째]\")\n",
    "            ax.set_ylabel(\" Pressure [hPa]\")\n",
    "            ax.set_xlim(-86,86)\n",
    "            ax.set_xticks((80,60,40,20,0,-20,-40,-60,-80))\n",
    "            ax.set_xticklabels([\"80N\",\"60N\",\"40N\",\"20N\",\"0\",\"20S\",\"40S\",\"60S\",\"80S\"])\n",
    "            ax.grid()\n",
    "            cbar = plt.colorbar(cs,orientation='vertical', shrink=0.9,ticks=np.linspace(var_min,var_max,15))\n",
    "            cbar.set_label(ylabel,rotation=-90,labelpad=25)\n",
    "            #plt.gca().invert_yaxis()\n",
    "            plt.title(title_var+\" (\"+name_files[i]+\"-\"+name_files[j]+\") \\n\",fontweight=\"bold\")\n",
    "            plt.savefig(\"grafici/\"+title_var+\" (\"+name_files[i]+\"-\"+name_files[j]+\")\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def all_graph_globe(var,title_var,ylabel,name_files,path_array,lon,lat,cost,proj_type,end,step,color=plt.cm.jet):\n",
    "    data_globe=[[cost*i for i in Dataset(path_array[j]+name_files[j]+\"_YM_\"+str(step[j])+\"YM_\"+\\\n",
    "                                         str(end[j])+\"Y_\"+var+\".nc\").variables[var][0]]for j in \\\n",
    "                range(0,len(name_files))]\n",
    "    #print(math.factorial(len(name_files))/(math.factorial(len(name_files)-2)*math.factorial(2)))\n",
    "    min_max=np.zeros((int(math.factorial(len(name_files))/(math.factorial(len(name_files)-2)*\\\n",
    "                                                           math.factorial(2))),2))\n",
    "    #print(np.shape(data_globe))\n",
    "    #print(np.reshape(data_globe[0],[nlat,nlon])[0])\n",
    "    count=0\n",
    "    for i in range(0,len(name_files)):\n",
    "        for j in range(i+1,len(name_files)):\n",
    "            min_max[count]=[np.min(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon])),\\\n",
    "                            np.max(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]))]\n",
    "            count+=1\n",
    "    #print(min_max)\n",
    "    max_lim=int(np.max(min_max)+1)\n",
    "    min_lim=int(np.min(min_max)-1)\n",
    "    lim=np.max([np.abs(min_lim),np.abs(max_lim)])\n",
    "    for i in range(0,len(name_files)):\n",
    "        for j in range(i+1,len(name_files)):\n",
    "            max_lim=int(np.max(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]))+1)\n",
    "            min_lim=int(np.min(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]))-1)\n",
    "            lim=np.max([np.abs(min_lim),np.abs(max_lim)])\n",
    "            graph_globe(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]),lons[i],\\\n",
    "                        lats[i],proj_type,True,title_var+\" (\"+name_files[i]+\"-\"+name_files[j]+\")\",ylabel,\\\n",
    "                        -lim,lim,15,cmap=color)\n",
    "            #print(np.max(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon])),np.min(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon])))\n",
    "    return data_globe\n",
    "\n",
    "def all_graph_globe2(data_globe,title_var,ylabel,lon,lat,proj_type):\n",
    "    min_max=np.zeros((int(math.factorial(len(name_files))/(math.factorial(len(name_files)-2)\\\n",
    "                                                           *math.factorial(2))),2))\n",
    "    count=0\n",
    "    for i in range(0,len(data_globe)):\n",
    "        for j in range(i+1,len(data_globe)):\n",
    "            min_max[count]=[np.min(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon])),\\\n",
    "                            np.max(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]))]\n",
    "            count+=1\n",
    "    #print(min_max)\n",
    "    max_lim=int(np.max(min_max)+1)\n",
    "    min_lim=int(np.min(min_max)-1)\n",
    "    lim=np.max([np.abs(min_lim),np.abs(max_lim)])\n",
    "    for i in range(0,len(data_globe)):\n",
    "        for j in range(i+1,len(data_globe)):\n",
    "            max_lim=int(np.max(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]))+1)\n",
    "            min_lim=int(np.min(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]))-1)\n",
    "            lim=np.max([np.abs(min_lim),np.abs(max_lim)])\n",
    "            graph_globe(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon]),lons[i],lats[i]\\\n",
    "                        ,proj_type,True,title_var+\" (\"+name_files[i]+\"-\"+name_files[j]+\")\",ylabel,-lim,\\\n",
    "                        lim,15)\n",
    "            #print(np.max(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon])),np.min(np.reshape(data_globe[i],[nlat,nlon])-np.reshape(data_globe[j],[nlat,nlon])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
